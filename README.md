# Chatbot Classification Project
    I.STRUCTURE DU PROJET 
       
       
        chatbot_classification/
â”‚
â”œâ”€â”€ .env                                # ðŸ” ClÃ©s API et infos sensibles
â”œâ”€â”€ requirements.txt                    # ðŸ“¦ DÃ©pendances Python
â”œâ”€â”€ README.md                           # ðŸ“˜ Documentation projet
â”œâ”€â”€ main.py                             # ðŸš€ EntrÃ©e principale (test global ou dÃ©mo)
â”‚
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ structured/                     # ðŸ“Š DonnÃ©es PostgreSQL (CSV / SQL)
â”‚   â”‚   â”œâ”€â”€ cleaned/
â”‚   â”‚   â””â”€â”€ structure_banque.sql
â”‚   â””â”€â”€ unstructured/                  # ðŸ“„ DonnÃ©es MongoDB (PDF, emails, .txtâ€¦)
â”‚       â”œâ”€â”€ raw/
â”‚       â””â”€â”€ cleaned/
â”‚
â”œâ”€â”€ models/                             # ðŸ¤– ModÃ¨les LLM locaux (.gguf) ou checkpoints
â”‚
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_structured.txt            # ðŸ“ Prompt de classification (F, C, R, O)
â”‚   â””â”€â”€ prompt_unstructured.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chatbot/                        # ðŸ’¬ Logique du chatbot
â”‚   â”‚   â””â”€â”€ chatbot_engine.py
â”‚
â”‚   â”œâ”€â”€ classification/                # ðŸ” Code de classification
â”‚   â”‚   â”œâ”€â”€ test_md.py
â”‚   â”‚   â””â”€â”€ test_pg.py
â”‚
â”‚
â”‚   â”œâ”€â”€ database/                      # ðŸ›¢ï¸ Connexion PostgreSQL & MongoDB
â”‚   â”‚   â”œâ”€â”€ postgres_utils.py
â”‚   â”‚   â””â”€â”€ mongo_utils.py
â”‚
â”‚   â”œâ”€â”€ dashboard/                     # ðŸ“Š Interface utilisateur (Streamlit ou autre)
â”‚   â”‚   â”œâ”€â”€ app.py                       # Test simple de prompt sans interface

â”‚   â””â”€â”€ utils/                         # ðŸ§° Fonctions utilitaires
â”‚       â””â”€â”€ helpers.py
â”‚

    II.REQUIREMENTS 

    # ðŸ“š LLM + LangChain
langchain>=0.1.17
langchain-community>=0.0.34
langchain-core>=0.1.34
google-generativeai>=0.3.2          # pour Gemini
transformers                        # si tu veux tester HF ou LLM local plus tard
llama-cpp-python                    # si tu utilises llama.cpp

# ðŸ§  Embeddings & vector search
faiss-cpu                          # moteur vectoriel rapide

# ðŸ—ƒï¸ Bases de donnÃ©es
psycopg2-binary                    # PostgreSQL
pymongo                            # MongoDB

# ðŸŒ Interface utilisateur
streamlit                          # dashboard interactif

# ðŸ§ª Tests
pytest

# ðŸ”§ Utilitaires
python-dotenv                      # pour charger .env
PyYAML                             # pour parser les fichiers YAML

# ðŸ“Œ Optionnel mais utile
tqdm                               # barre de progression
rich                               # affichage CLI Ã©lÃ©gant

    III.ETAPES D'EXECUTION DU PROJET
        1.CREATION D'UN ENVIRONNEMENT VIRTUEL
            PS C:\Users\smart\Desktop\UIR\STAGE\chatbot_classification>python -m venv llama_env
                                                                    .\llama_env\Scripts\activate
        
        2.INSTALLATION DES EXIGENCES
            (llama_env) PS C:\Users\smart\Desktop\UIR\STAGE\chatbot_classification>pip install -r requirements.txt

        3.VERIFICATION DU FICHIER .env ET L'ADAPTER SELON VOUS

        4.VERIFICATION DES DONNEES STRUCTURES ET NON STRUCTURES ET ASSURER LEUR IMPORTATION (POSTGRES,MONGODB)

        5.LANCEMENT DU TEST
            (llama_env) PS C:\Users\smart\Desktop\UIR\STAGE\chatbot_classification> streamlit run .\src\dashboard\app.py

IMPORTANT !! : IL FAUT IMPORTER LES DONNES (FICHIER ./data) DANS LES BASES DE DONNEES (POSTGRES:DONNEES STRUCTURES / MONGODB:DONNEES NON STRUCTURES) 
